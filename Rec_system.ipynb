{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://umair-iftikhar.medium.com/building-a-simple-recommendation-system-with-item-item-collaborative-filtering-in-python-3baae5179c52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "USER_ID = 240567         # user_id for which we are going to recommend movies\n",
    "TOP = 20                 # number of movies to recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books:  50423\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 22.2 GiB for an array with shape (59190, 50423) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Create an empty dataframe\u001b[39;00m\n\u001b[0;32m     28\u001b[0m df_books \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39musers, columns\u001b[38;5;241m=\u001b[39mbooks)\n\u001b[1;32m---> 29\u001b[0m df_books \u001b[38;5;241m=\u001b[39m \u001b[43mdf_books\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# fill the dataframe with the ratings\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_filter\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\frame.py:5627\u001b[0m, in \u001b[0;36mDataFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   5616\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   5617\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39mfillna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m   5618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfillna\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5625\u001b[0m     downcast: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5626\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5630\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5631\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\generic.py:6927\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   6924\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m result  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   6925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 6927\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[0;32m   6929\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6930\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   6932\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotna(), value)\u001b[38;5;241m.\u001b[39m_mgr\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\internals\\managers.py:441\u001b[0m, in \u001b[0;36mBaseBlockManager.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_no_reference_block(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks))\n\u001b[0;32m    438\u001b[0m     ):\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\internals\\managers.py:348\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1199\u001b[0m, in \u001b[0;36mBlock.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputmask(mask\u001b[38;5;241m.\u001b[39mT, value)\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;66;03m# without _downcast, we would break\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;66;03m#  test_fillna_dtype_conversion_equiv_replace\u001b[39;00m\n\u001b[1;32m-> 1199\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_downcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# Note: blk._maybe_downcast vs self._maybe_downcast(nbs)\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;66;03m#  makes a difference bc blk may have object dtype, which has\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;66;03m#  different behavior in _maybe_downcast.\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extend_blocks(\n\u001b[0;32m   1205\u001b[0m     [blk\u001b[38;5;241m.\u001b[39m_maybe_downcast([blk], downcast\u001b[38;5;241m=\u001b[39mdowncast) \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m nbs]\n\u001b[0;32m   1206\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1153\u001b[0m, in \u001b[0;36mBlock.where\u001b[1;34m(self, other, cond, _downcast)\u001b[0m\n\u001b[0;32m   1148\u001b[0m             other \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(other)\u001b[38;5;241m.\u001b[39mreshape(values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1149\u001b[0m             \u001b[38;5;66;03m# If lengths don't match (or len(other)==1), we will raise\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m             \u001b[38;5;66;03m#  inside expressions.where, see test_series_where\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m \n\u001b[0;32m   1152\u001b[0m         \u001b[38;5;66;03m# Note: expressions.where may upcast.\u001b[39;00m\n\u001b[1;32m-> 1153\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mexpressions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43micond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;66;03m# The np_can_hold_element check _should_ ensure that we always\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m         \u001b[38;5;66;03m#  have result.dtype == self.dtype here.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:259\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(cond, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mEvaluate the where condition cond on a and b.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    Whether to try to use numexpr.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m _where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m use_numexpr \u001b[38;5;28;01melse\u001b[39;00m _where_standard(cond, a, b)\n",
      "File \u001b[1;32mc:\\Users\\alber\\miniconda3\\envs\\deepLearning\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:173\u001b[0m, in \u001b[0;36m_where_standard\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_where_standard\u001b[39m(cond, a, b):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for extracting ndarray if necessary\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 22.2 GiB for an array with shape (59190, 50423) and data type object"
     ]
    }
   ],
   "source": [
    "# Load the books dataset\n",
    "df_books_name = pd.read_csv(\"BX-Books.csv\", on_bad_lines='skip', sep=';',low_memory=False)\n",
    "df_books_name = df_books_name.iloc[:, :-3]\n",
    "df_books_name = df_books_name.set_index('ISBN')\n",
    "df_books_name = df_books_name.rename_axis(None)\n",
    "\n",
    "# Load the ratings dataset\n",
    "df = pd.read_csv(\"BX-Book-Ratings.csv\", on_bad_lines='skip', sep=';')\n",
    "df = df[df['Book-Rating'] != 0]\n",
    "\n",
    "#Remove the books that are not in the books_name dataset\n",
    "df = df[df['ISBN'].isin(df_books_name.index)]\n",
    "\n",
    "\n",
    "# Cut the dataframe\n",
    "# cut = 200000\n",
    "# df = df[:cut]\n",
    "\n",
    "# Remove the books with less than 10 ratings\n",
    "df_filter = df.groupby('ISBN').filter(lambda x: len(x) >= 2)\n",
    "\n",
    "\n",
    "# Unique list of all the users and books\n",
    "users = df_filter['User-ID'].unique()\n",
    "books = df_filter['ISBN'].unique()\n",
    "print(\"Number of books: \", len(books))\n",
    "# Create an empty dataframe\n",
    "df_books = pd.DataFrame(index=users, columns=books)\n",
    "df_books = df_books.fillna(0)\n",
    "\n",
    "# fill the dataframe with the ratings\n",
    "for index, row in df_filter.iterrows():\n",
    "    df_books.at[row['User-ID'], row['ISBN']] = row['Book-Rating']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>038550120X</th>\n",
       "      <th>0060517794</th>\n",
       "      <th>0671537458</th>\n",
       "      <th>0679776818</th>\n",
       "      <th>0684867621</th>\n",
       "      <th>0451166892</th>\n",
       "      <th>0380711524</th>\n",
       "      <th>0345443683</th>\n",
       "      <th>043935806X</th>\n",
       "      <th>055310666X</th>\n",
       "      <th>...</th>\n",
       "      <th>1551666561</th>\n",
       "      <th>0553273906</th>\n",
       "      <th>0875421318</th>\n",
       "      <th>0380973820</th>\n",
       "      <th>0449242072</th>\n",
       "      <th>0452283795</th>\n",
       "      <th>067102731X</th>\n",
       "      <th>0060294671</th>\n",
       "      <th>1853262102</th>\n",
       "      <th>0441005667</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276744</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276747</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276754</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276762</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276683</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276685</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276704</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39365 rows × 5444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        038550120X  0060517794  0671537458  0679776818  0684867621  \\\n",
       "276744           7           0           0           0           0   \n",
       "276747           0           9           9           8           0   \n",
       "276754           0           0           0           0           8   \n",
       "276755           0           0           0           0           0   \n",
       "276762           0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "276683           0           0           0           0           0   \n",
       "276685           0           0           0           0           0   \n",
       "276688           0           0           0           0           0   \n",
       "276704           0           0           0           0           0   \n",
       "276709           0           0           0           0           0   \n",
       "\n",
       "        0451166892  0380711524  0345443683  043935806X  055310666X  ...  \\\n",
       "276744           0           0           0           0           0  ...   \n",
       "276747           0           0           0           0           0  ...   \n",
       "276754           0           0           0           0           0  ...   \n",
       "276755           5           0           0           0           0  ...   \n",
       "276762           0           5           0           0           0  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "276683           0           0           0           0           0  ...   \n",
       "276685           0           0           0           0           0  ...   \n",
       "276688           0           0           0           0           0  ...   \n",
       "276704           0           0           0           0           0  ...   \n",
       "276709           0           0           0           0           0  ...   \n",
       "\n",
       "        1551666561  0553273906  0875421318  0380973820  0449242072  \\\n",
       "276744           0           0           0           0           0   \n",
       "276747           0           0           0           0           0   \n",
       "276754           0           0           0           0           0   \n",
       "276755           0           0           0           0           0   \n",
       "276762           0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "276683           0           0           0           0           0   \n",
       "276685           0           0           0           0           0   \n",
       "276688           0           0           0           0           0   \n",
       "276704           0           0           0           0           0   \n",
       "276709           0           0           0           0           0   \n",
       "\n",
       "        0452283795  067102731X  0060294671  1853262102  0441005667  \n",
       "276744           0           0           0           0           0  \n",
       "276747           0           0           0           0           0  \n",
       "276754           0           0           0           0           0  \n",
       "276755           0           0           0           0           0  \n",
       "276762           0           0           0           0           0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "276683           0           0           0           0           0  \n",
       "276685           0           0           0           0           0  \n",
       "276688           0           0           0           0           0  \n",
       "276704           0           0           0           0           0  \n",
       "276709           0           0           0           0           0  \n",
       "\n",
       "[39365 rows x 5444 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 books by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top most rated books in the dataset in this fomrat (ISBN, book title, authors, average rating, number of ratings)\n",
      "\n",
      "ISBN        Book Title                                                        Authors            Average Rating    Number of Ratings\n",
      "----------  ----------------------------------------------------------------  ---------------  ----------------  -------------------\n",
      "0316666343  The Lovely Bones: A Novel                                         Alice Sebold                 8.19                  707\n",
      "0971880107  Wild Animus                                                       Rich Shapero                 4.39                  581\n",
      "0385504209  The Da Vinci Code                                                 Dan Brown                    8.44                  487\n",
      "0312195516  The Red Tent (Bestselling Backlist)                               Anita Diamant                8.18                  383\n",
      "0060928336  Divine Secrets of the Ya-Ya Sisterhood: A Novel                   Rebecca Wells                7.89                  320\n",
      "059035342X  Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))  J. K. Rowling                8.94                  313\n",
      "0142001740  The Secret Life of Bees                                           Sue Monk Kidd                8.45                  307\n",
      "0446672211  Where the Heart Is (Oprah's Book Club (Paperback))                Billie Letts                 8.14                  295\n",
      "044023722X  A Painted House                                                   John Grisham                 7.34                  281\n",
      "0452282152  Girl with a Pearl Earring                                         Tracy Chevalier              7.98                  278\n",
      "\n",
      "Top users with most ratings in this format (User-ID, number of ratings)\n",
      "\n",
      "11676 1894\n",
      "16795 339\n",
      "98391 315\n",
      "153662 302\n",
      "95359 283\n",
      "104636 271\n",
      "114368 266\n",
      "123883 203\n",
      "60244 203\n",
      "158295 202\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Top most rated books in the dataset in this fomrat (ISBN, book title, authors, average rating, number of ratings)\\n\")\n",
    "top = df_filter['ISBN'].value_counts().head(10)\n",
    "\n",
    "table_data = []\n",
    "for i in range(10):\n",
    "    book = df_books.loc[:, top.index[i]].values.T\n",
    "    mean = np.round(np.mean(book[book != 0]), 2)\n",
    "    table_data.append([top.index[i], df_books_name.loc[top.index[i]]['Book-Title'], df_books_name.loc[top.index[i]]['Book-Author'], mean, top.values[i]])\n",
    "\n",
    "table_headers = [\"ISBN\", \"Book Title\", \"Authors\", \"Average Rating\", \"Number of Ratings\"]\n",
    "print(tabulate(table_data, headers=table_headers))\n",
    "\n",
    "#top users with most ratings\n",
    "top = df_filter['User-ID'].value_counts().head(30)\n",
    "print(\"\\nTop users with most ratings in this format (User-ID, number of ratings)\\n\")\n",
    "for i in range(10):\n",
    "    print(top.index[i], top.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute item-item similarity\n",
    "item_similarity = cosine_similarity(df_books.T)\n",
    "\n",
    "# Example user's interactions\n",
    "user_interactions = df_books.loc[USER_ID]\n",
    "# Calculate item scores based on user's interactions and item similarity\n",
    "item_scores = user_interactions.dot(item_similarity)\n",
    "\n",
    "# Set the scores of the items that the user has already interacted with to 0\n",
    "item_scores[user_interactions > 0] = user_interactions[user_interactions > 0]\n",
    "\n",
    "# Normalize the scores between 0 and 10\n",
    "item_scores = (item_scores - item_scores.min()) / (item_scores.max() - item_scores.min()) * 10\n",
    "\n",
    "#set to 0 the items that the user has already interacted with\n",
    "item_scores[user_interactions > 0] = 0\n",
    "\n",
    "# Sort items by score and recommend the top-n\n",
    "recommended_items = np.argsort(item_scores)[::-1][:TOP]\n",
    "print(item_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 recommended books for user 240567:\n",
      "Book Title                                                             Book Author           ISBN          Predicted Rating\n",
      "---------------------------------------------------------------------  --------------------  ----------  ------------------\n",
      "Four To Score (A Stephanie Plum Novel)                                 Janet Evanovich       0312966970            10\n",
      "Three To Get Deadly : A Stephanie Plum Novel (A Stephanie Plum Novel)  Janet Evanovich       0312966091             9.56228\n",
      "When the Bough Breaks (Alex Delaware Novels (Paperback))               Jonathan Kellerman    0553569619             8.47101\n",
      "Hawaii                                                                 James A. Michener     0449213358             8.12772\n",
      "Loving                                                                 Danielle Steel        0440146577             8.07582\n",
      "Turbulence                                                             John J. Nance         0515134864             8.03064\n",
      "Irresistible Forces                                                    Danielle Steel        0440224861             7.82686\n",
      "Fingersmith                                                            Sarah Waters          1573222038             7.71019\n",
      "Until the Real Thing Comes Along (Ballantine Reader's Circle)          ELIZABETH BERG        034543739X             7.54689\n",
      "Special Delivery: A Novel                                              Danielle Steel        0440224810             7.44731\n",
      "Mixed Blessings                                                        DANIELLE STEEL        0440214114             7.43518\n",
      "Melody (Logan)                                                         V.C. Andrews          0671534718             7.31445\n",
      "Seven Up (A Stephanie Plum Novel)                                      Janet Evanovich       0312980140             7.26363\n",
      "The Town                                                               Bentley Little        0451200152             7.2385\n",
      "Bright lights, big city: A novel                                       Jay McInerney         0394756886             7.17181\n",
      "Dave Barry Turns 40                                                    Dave Barry            0517577550             7.16137\n",
      "Step-Ball-Change                                                       Jeanne Ray            0451410742             7.09754\n",
      "These Happy Golden Years (Little House)                                Laura Ingalls Wilder  0064400085             6.85882\n",
      "Eureka                                                                 William Diehl         0345411471             6.82376\n",
      "Season of Passion                                                      Danielle Steel        0440177049             6.82053\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"Top \" + str(TOP) + \" recommended books for user \" + str(USER_ID) + \":\")\n",
    "\n",
    "table_data = []\n",
    "for item in recommended_items:\n",
    "    Isnb = df_books.columns[item]\n",
    "    title = df_books_name.loc[Isnb]\n",
    "    Pred = item_scores[item]\n",
    "    table_data.append([title['Book-Title'], title['Book-Author'], Isnb, Pred])\n",
    "\n",
    "\n",
    "\n",
    "table_headers = [\"Book Title\", \"Book Author\", \"ISBN\",\"Predicted Rating\"]\n",
    "print(tabulate(table_data, headers=table_headers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions User ratings for a book\n",
    "#pick random book id from the list of books\n",
    "\n",
    "# book_id = books[np.random.randint(0, len(books))]\n",
    "\n",
    "# book_title = df_books_name.loc[book_id]['Book-Title']\n",
    "# book_ratings = df_books[book_id]\n",
    "# book_similarity = item_similarity[books == book_id]\n",
    "# user_ratings = df_books.loc[USER_ID]\n",
    "# predicted_rating = user_ratings.dot(book_similarity.T)\n",
    "# print(\"Predicted rating for book '\" + book_title + \"' for user \" + str(USER_ID) + \": \" + str(predicted_rating[0]))\n",
    "# print(\"Actual rating for book '\" + book_title + \"' for user \" + str(USER_ID) + \": \" + str(book_ratings[USER_ID]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Based Collaborative Filtering\n",
    "\n",
    "In user-based collaborative filtering, we recommend items to a user based on the preferences of similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 0 on item 2: 0.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample user-item interaction matrix (rows are users, columns are items)\n",
    "ratings = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [0, 0, 5, 4],\n",
    "    [0, 3, 4, 5]\n",
    "])\n",
    "\n",
    "# Compute user-user similarity matrix\n",
    "user_similarity = cosine_similarity(ratings)\n",
    "\n",
    "def predict_user_based(user, item, ratings, user_similarity):\n",
    "    # Mean rating for the target user\n",
    "    mean_user_rating = ratings[user].mean()\n",
    "    # Compute the weighted sum of ratings\n",
    "    weighted_sum = np.sum(user_similarity[user] * (ratings[:, item] - ratings.mean(axis=1)))\n",
    "    similarity_sum = np.sum(user_similarity[user])\n",
    "\n",
    "    if similarity_sum == 0:\n",
    "        return mean_user_rating\n",
    "\n",
    "    # Predicted rating\n",
    "    return mean_user_rating + (weighted_sum / similarity_sum)\n",
    "\n",
    "# Predict rating for user 0 on item 2\n",
    "predicted_rating = predict_user_based(0, 2, ratings, user_similarity)\n",
    "print(f\"Predicted rating for user 0 on item 2: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Item-Based Collaborative Filtering\n",
    "In item-based collaborative filtering, we recommend items similar to those the user has liked in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_item_rating \u001b[38;5;241m+\u001b[39m (weighted_sum \u001b[38;5;241m/\u001b[39m similarity_sum)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Predict rating for user 0 on item 2\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m predicted_rating \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_item_based\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_similarity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted rating for user 0 on item 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_rating\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m, in \u001b[0;36mpredict_item_based\u001b[1;34m(user, item, ratings, item_similarity)\u001b[0m\n\u001b[0;32m     18\u001b[0m mean_item_rating \u001b[38;5;241m=\u001b[39m ratings[:, item]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the weighted sum of ratings\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m weighted_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(item_similarity[item] \u001b[38;5;241m*\u001b[39m (\u001b[43mratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     21\u001b[0m similarity_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(item_similarity[item])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similarity_sum \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (5,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample user-item interaction matrix (rows are users, columns are items)\n",
    "ratings = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [0, 0, 5, 4],\n",
    "    [0, 3, 4, 5]\n",
    "])\n",
    "\n",
    "# Compute item-item similarity matrix\n",
    "item_similarity = cosine_similarity(ratings.T)\n",
    "\n",
    "def predict_item_based(user, item, ratings, item_similarity):\n",
    "    # Mean rating for the target item\n",
    "    mean_item_rating = ratings[:, item].mean()\n",
    "    # Compute the weighted sum of ratings\n",
    "    weighted_sum = np.sum(item_similarity[item] * (ratings[user] - ratings.mean(axis=1)))\n",
    "    similarity_sum = np.sum(item_similarity[item])\n",
    "\n",
    "    if similarity_sum == 0:\n",
    "        return mean_item_rating\n",
    "\n",
    "    # Predicted rating\n",
    "    return mean_item_rating + (weighted_sum / similarity_sum)\n",
    "\n",
    "# Predict rating for user 0 on item 2\n",
    "predicted_rating = predict_item_based(0, 2, ratings, item_similarity)\n",
    "print(f\"Predicted rating for user 0 on item 2: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Setup Spark session\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBookRecommendation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m df_books_name \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBX-Books.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\java_gateway.py:104\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 104\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[0;32m    108\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAVA_GATEWAY_EXITED\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[0;32m    110\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Setup Spark session\n",
    "spark = SparkSession.builder.appName(\"BookRecommendation\").getOrCreate()\n",
    "\n",
    "# Load the data\n",
    "df_books_name = pd.read_csv(\"BX-Books.csv\", on_bad_lines='skip', sep=';', low_memory=False)\n",
    "df_books_name = df_books_name.iloc[:, :-3]\n",
    "df_books_name = df_books_name.set_index('ISBN')\n",
    "df_books_name = df_books_name.rename_axis(None)\n",
    "\n",
    "df_books_name_spark = spark.createDataFrame(df_books_name.reset_index())\n",
    "\n",
    "df = pd.read_csv(\"BX-Book-Ratings.csv\", on_bad_lines='skip', sep=';')\n",
    "df = df[df['Book-Rating'] != 0]\n",
    "df_spark = spark.createDataFrame(df)\n",
    "df_spark = df_spark.filter(df_spark['ISBN'].isin([row['index'] for row in df_books_name_spark.select('index').collect()]))\n",
    "\n",
    "# Filter and prepare the data\n",
    "df_filter_spark = df_spark.groupBy('ISBN').count().filter('count >= 10').select('ISBN')\n",
    "df_filter_spark = df_spark.join(df_filter_spark, on='ISBN')\n",
    "\n",
    "users = df_filter_spark.select('User-ID').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "books = df_filter_spark.select('ISBN').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "schema = StructType([StructField('User-ID', IntegerType(), True)] + [StructField(book, FloatType(), True) for book in books])\n",
    "df_books_spark = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "\n",
    "for row in df_filter_spark.collect():\n",
    "    df_books_spark = df_books_spark.withColumn(row['ISBN'], F.when(col('User-ID') == row['User-ID'], row['Book-Rating']).otherwise(col(row['ISBN'])))\n",
    "\n",
    "# Compute item-item similarity\n",
    "df_books_pandas = df_books_spark.toPandas().fillna(0)\n",
    "item_similarity = cosine_similarity(df_books_pandas.set_index('User-ID').T)\n",
    "\n",
    "# User interactions and item scores\n",
    "USER_ID = 104636\n",
    "TOP = 3\n",
    "user_interactions = df_books_pandas[df_books_pandas['User-ID'] == USER_ID].drop('User-ID', axis=1).values.flatten()\n",
    "item_scores = user_interactions.dot(item_similarity)\n",
    "\n",
    "item_scores[user_interactions > 0] = 0\n",
    "item_scores = (item_scores - item_scores.min()) / (item_scores.max() - item_scores.min()) * 10\n",
    "item_scores[user_interactions > 0] = 0\n",
    "\n",
    "recommended_items = np.argsort(item_scores)[::-1][:TOP]\n",
    "\n",
    "# Display recommended items\n",
    "table_data = []\n",
    "for item in recommended_items:\n",
    "    Isnb = df_books_pandas.columns[item + 1]  # +1 because the first column is 'User-ID'\n",
    "    title = df_books_name.loc[Isnb]\n",
    "    Pred = item_scores[item]\n",
    "    table_data.append([title['Book-Title'], title['Book-Author'], Isnb, Pred])\n",
    "\n",
    "table_headers = [\"Book Title\", \"Book Author\", \"ISBN\", \"Predicted Rating\"]\n",
    "print(tabulate(table_data, headers=table_headers))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
